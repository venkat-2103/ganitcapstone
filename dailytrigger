import requests
import pandas as pd
from datetime import datetime, timedelta
import boto3
import io

# Step 1: Get the list of all mutual fund schemes
all_schemes_url = "https://api.mfapi.in/mf"

response = requests.get(all_schemes_url)
if response.status_code == 200:
    all_schemes = response.json()
else:
    print("Failed to fetch the list of schemes")
    all_schemes = []

# Step 2: Fetch data up to today
day = (datetime.today() - timedelta(days=1)).strftime('%d-%m-%Y')
daily_data = []

schemes_to_fetch = all_schemes[0:]
total_schemes = len(schemes_to_fetch)

for i, scheme in enumerate(schemes_to_fetch, start=1):
    scheme_code = scheme['schemeCode']
    historical_data_url = f"https://api.mfapi.in/mf/{scheme_code}"

    response = requests.get(historical_data_url)
    if response.status_code == 200:
        data = response.json()
        if 'data' in data:
            for entry in data['data']:
                if entry['date'] == day:
                    entry['schemeCode'] = scheme_code
                    entry['schemeName'] = data['meta']['scheme_name']
                    entry['fund_house'] = data['meta']['fund_house']
                    entry['scheme_type'] = data['meta']['scheme_type']
                    entry['scheme_category'] = data['meta']['scheme_category']
                    daily_data.append(entry)
        print(f"Processed {scheme_code}: {i}/{total_schemes}")
    else:
        print(f"Failed to fetch data for scheme: {scheme_code}")

# Convert data into a DataFrame
df = pd.DataFrame(daily_data)

# Data Cleansing
df = df.groupby(['date', 'nav', 'fund_house', 'scheme_type', 'scheme_category', 'schemeCode', 'schemeName']).size().reset_index(name='count')
df = df.drop('count', axis=1)
df['scheme_category'] = df['scheme_category'].str.upper()
df['date'] = pd.to_datetime(df['date'], errors='coerce', dayfirst=True)
df = df.sort_values(by='date', ascending=False)

# Clean scheme_category
def categorize(scheme):
    if 'EQUITY SCHEME' in scheme:
        return 'EQUITY SCHEME'
    elif 'DEBT SCHEME' in scheme:
        return 'DEBT SCHEME'
    elif 'HYBRID SCHEME' in scheme:
        return 'HYBRID SCHEMES'
    elif 'SOLUTION ORIENTED SCHEME - RETIREMENT FUND' in scheme:
        return 'SOLUTION ORIENTED SCHEME RETIREMENT'
    elif 'SOLUTION ORIENTED SCHEME - CHILDRENâ€™S FUND' in scheme:
        return 'SOLUTION ORIENTED SCHEME CHILDREN'
    elif 'OTHER SCHEME' in scheme:
        return 'OTHERS'
    elif 'FORMERLY SUPER INSTITUTIONAL PLAN' in scheme:
        return 'FORMERLY SUPER INSTITUTIONAL PLAN'
    elif 'FORMERLY KNOWN AS IIFL MUTUAL FUND' in scheme:
        return 'FORMERLY KNOWN AS IIFL MUTUAL FUND'
    elif any(keyword in scheme for keyword in ['DAYS', 'PLAN', 'DAILY', 'HALF YEARLY', 'ANNUAL', 'COMPULSORY']):
        return 'DURATION/PLAN'
    elif 'DIRECT' in scheme or 'PAYOUT' in scheme:
        return 'DIRECT/PAYOUT'
    elif 'IDF' in scheme or 'GROWTH' in scheme or 'LIQUID' in scheme:
        return 'IDF/GROWTH/LIQUID'
    else:
        return 'MISCELLANEOUS'

df['scheme_category'] = df['scheme_category'].apply(categorize)

# Clean scheme_type
def clean_text(scheme):
    if 'Mutual Fund' in scheme:
        return 'Mutual Fund'
    elif 'Open Ended' in scheme:
        return 'Open Ended Scheme'
    elif 'Close Ended' in scheme:
        return 'Close Ended Scheme'
    elif 'Interval Fund' in scheme:
        return 'Interval Fund'
    elif 'Debt' in scheme or 'FMP' in scheme:
        return 'Debt Scheme'
    elif 'Hybrid' in scheme:
        return 'Hybrid Scheme'
    elif 'Equity' in scheme:
        return 'Equity Scheme'
    elif 'Index Fund' in scheme:
        return 'Index Fund'
    elif 'Liquid' in scheme or 'Ultra Short Duration' in scheme:
        return 'Liquid/Ultra Short Duration Fund'
    elif 'Plan' in scheme or 'Days' in scheme:
        return 'Plan/Duration'
    else:
        return 'Uncategorized'
                    
df['scheme_type'] = df['scheme_type'].apply(clean_text)
df.rename(columns={'schemeCode':'scheme_code','schemeName':'scheme_name'}, inplace=True)

# Store CSV locally
s3_client = boto3.client('s3')

# Step 3: Upload daily data CSV file to S3 bucket
# Save DataFrame to CSV in memory
csv_buffer = io.StringIO()
df.to_csv(csv_buffer, index=False)
csv_buffer.seek(0)
            
# Upload CSV to S3
s3_client.put_object(Bucket='capstone-daily', Key=f'dailycsv/dailyfile-{day}.csv', Body=csv_buffer.getvalue())

# Step 4: Generate and upload daily summary report
summary_stats = {
    'Metric': ['Mean NAV', 'Count NAV', 'Max NAV', 'Min NAV', 'Unique Fund House', 'Count Unique Fund House', 'Unique Scheme Type', 'Count Unique Scheme Type', 'Unique Scheme Category', 'Count Unique Scheme Category'],
    'Value': []
}

# Mean, Count, Max, Min for 'nav'
if 'nav' in df.columns:
    summary_stats['Value'].append(df['nav'].astype(float).mean())
    summary_stats['Value'].append(df['nav'].astype(float).count())
    summary_stats['Value'].append(df['nav'].astype(float).max())
    summary_stats['Value'].append(df['nav'].astype(float).min())
else:
    summary_stats['Value'].extend(['N/A']*4)

# Unique count and count of unique for 'fund_house'
if 'fund_house' in df.columns:
    unique_fund_house = df['fund_house'].nunique()
    count_unique_fund_house = df['fund_house'].nunique()
    summary_stats['Value'].append(unique_fund_house)
    summary_stats['Value'].append(count_unique_fund_house)
else:
    summary_stats['Value'].extend(['N/A']*2)

# Unique count and count of unique for 'scheme_type'
if 'scheme_type' in df.columns:
    unique_scheme_type = df['scheme_type'].nunique()
    count_unique_scheme_type = df['scheme_type'].nunique()
    summary_stats['Value'].append(unique_scheme_type)
    summary_stats['Value'].append(count_unique_scheme_type)
else:
    summary_stats['Value'].extend(['N/A']*2)

# Unique count and count of unique for 'scheme_category'
if 'scheme_category' in df.columns:
    unique_scheme_category = df['scheme_category'].nunique()
    count_unique_scheme_category = df['scheme_category'].nunique()
    summary_stats['Value'].append(unique_scheme_category)
    summary_stats['Value'].append(count_unique_scheme_category)
else:
    summary_stats['Value'].extend(['N/A']*2)

summary_df = pd.DataFrame(summary_stats)

# Save summary DataFrame to CSV in memory
summary_csv_buffer = io.StringIO()
summary_df.to_csv(summary_csv_buffer, index=False)
summary_csv_buffer.seek(0)

# Upload summary CSV to S3
s3_client.put_object(Bucket='capstone-daily', Key=f'summary_reports/daily_summary-{day}.csv', Body=summary_csv_buffer.getvalue())
